<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Week 6 Disease Mapping III: Introduction to Fully Bayesian mapping | EPI 563: Spatial Epidemiology, Fall 2023</title>
<meta name="author" content="Michael Kramer">
<meta name="description" content="6.1 Getting Ready  6.1.1 Learning objectives   6.1.2 Additional Resources Waller LA, Carlin BP. Disease mapping. Chapman Hall/CRC handbooks Mod Stat methods. 2010;2010(1979):217–43. (posted on...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Week 6 Disease Mapping III: Introduction to Fully Bayesian mapping | EPI 563: Spatial Epidemiology, Fall 2023">
<meta property="og:type" content="book">
<meta property="og:description" content="6.1 Getting Ready  6.1.1 Learning objectives   6.1.2 Additional Resources Waller LA, Carlin BP. Disease mapping. Chapman Hall/CRC handbooks Mod Stat methods. 2010;2010(1979):217–43. (posted on...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Week 6 Disease Mapping III: Introduction to Fully Bayesian mapping | EPI 563: Spatial Epidemiology, Fall 2023">
<meta name="twitter:description" content="6.1 Getting Ready  6.1.1 Learning objectives   6.1.2 Additional Resources Waller LA, Carlin BP. Disease mapping. Chapman Hall/CRC handbooks Mod Stat methods. 2010;2010(1979):217–43. (posted on...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">EPI 563: Spatial Epidemiology, Fall 2023</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">How to use this eBook</a></li>
<li><a class="" href="download-ebook.html">Download eBook</a></li>
<li class="book-part">Getting ready…</li>
<li><a class="" href="software-installation.html">Software installation</a></li>
<li><a class="" href="installing-packages-for-this-course.html">Installing packages for this course</a></li>
<li class="book-part">Weekly Modules</li>
<li><a class="" href="locating-spatial-epidemiology.html"><span class="header-section-number">1</span> Locating Spatial Epidemiology</a></li>
<li><a class="" href="cartography-for-epidemiology-i.html"><span class="header-section-number">2</span> Cartography for Epidemiology I</a></li>
<li><a class="" href="cartography-for-epidemiology-ii-spatial-ethics.html"><span class="header-section-number">3</span> Cartography for Epidemiology II: Spatial Ethics</a></li>
<li><a class="" href="disease-mapping-i-aspatial-empirical-bayes.html"><span class="header-section-number">4</span> Disease Mapping I: Aspatial Empirical Bayes</a></li>
<li><a class="" href="disease-mapping-ii-spatial-empirical-bayes.html"><span class="header-section-number">5</span> Disease Mapping II: Spatial Empirical Bayes</a></li>
<li><a class="active" href="disease-mapping-iii-introduction-to-fully-bayesian-mapping.html"><span class="header-section-number">6</span> Disease Mapping III: Introduction to Fully Bayesian mapping</a></li>
<li><a class="" href="disease-mapping-iv-kernel-density-estimation.html"><span class="header-section-number">7</span> Disease Mapping IV: Kernel Density Estimation</a></li>
<li><a class="" href="spatial-structure-and-clustering-i-morans-i-and-lisa.html"><span class="header-section-number">8</span> Spatial Structure and Clustering I: Moran’s I and LISA</a></li>
<li><a class="" href="spatial-structure-and-clustering-ii-spatial-scan-statistics.html"><span class="header-section-number">9</span> Spatial Structure and Clustering II: Spatial scan statistics</a></li>
<li><a class="" href="spatreg1.html"><span class="header-section-number">10</span> Spatial Regression I: Spatializing aspatial regression residuals</a></li>
<li><a class="" href="spatial-regression-ii-spatial-econometric-regression.html"><span class="header-section-number">11</span> Spatial Regression II: Spatial econometric regression</a></li>
<li><a class="" href="spatial-regression-iii-geographically-weighted-regression.html"><span class="header-section-number">12</span> Spatial Regression III: Geographically Weighted Regression</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="reproducibility-and-projects-in-r.html"><span class="header-section-number">13</span> Reproducibility and Projects in R</a></li>
<li><a class="" href="introduction-to-rmarkdown.html"><span class="header-section-number">14</span> Introduction to rmarkdown</a></li>
<li><a class="" href="formatting-markdown-and-notebooks.html"><span class="header-section-number">15</span> Formatting Markdown and Notebooks</a></li>
<li><a class="" href="sf-overview.html"><span class="header-section-number">16</span> Tips for working with sf data class</a></li>
<li><a class="" href="dplyr.html"><span class="header-section-number">17</span> Tips for using dplyr</a></li>
<li><a class="" href="intro-tmap.html"><span class="header-section-number">18</span> Tips for using tmap</a></li>
<li><a class="" href="kde-extract.html"><span class="header-section-number">19</span> Using kernel density estimates to quantify an exposure for Spatial Epi</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mkram01/EPI563-SpatialEPI">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="disease-mapping-iii-introduction-to-fully-bayesian-mapping" class="section level1" number="6">
<h1>
<span class="header-section-number">Week 6</span> Disease Mapping III: Introduction to Fully Bayesian mapping<a class="anchor" aria-label="anchor" href="#disease-mapping-iii-introduction-to-fully-bayesian-mapping"><i class="fas fa-link"></i></a>
</h1>
<div id="getting-ready-4" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Getting Ready<a class="anchor" aria-label="anchor" href="#getting-ready-4"><i class="fas fa-link"></i></a>
</h2>
<div id="learning-objectives-5" class="section level3" number="6.1.1">
<h3>
<span class="header-section-number">6.1.1</span> Learning objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-5"><i class="fas fa-link"></i></a>
</h3>
</div>
<div id="additional-resources-5" class="section level3" number="6.1.2">
<h3>
<span class="header-section-number">6.1.2</span> Additional Resources<a class="anchor" aria-label="anchor" href="#additional-resources-5"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Waller LA, Carlin BP. Disease mapping. Chapman Hall/CRC handbooks Mod Stat methods. 2010;2010(1979):217–43. (posted on Canvas)</li>
<li><a href="https://cran.r-project.org/web/packages/CARBayes/vignettes/CARBayes.pdf"><code>CARBayes</code> package vignette</a></li>
<li><a href="https://cran.r-project.org/web/packages/CARBayes/vignettes/CARBayes.pdf"><code>CARBayesST</code> spatio-temporal vignette</a></li>
</ul>
</div>
<div id="important-vocabulary-5" class="section level3" number="6.1.3">
<h3>
<span class="header-section-number">6.1.3</span> Important Vocabulary<a class="anchor" aria-label="anchor" href="#important-vocabulary-5"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; width: 90%; margin-left: auto; margin-right: auto;  " id="tab:unnamed-chunk-2">
<caption style="caption-side: top; text-align: center;">
<span id="tab:unnamed-chunk-2">TABLE 1.2: </span> Vocabulary for Week 6</caption>
<col>
<col>
<tr>
<th style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(84, 153, 199); font-weight: bold;"><span style="color: rgb(255, 255, 255);">Term</span></th>
<th style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(84, 153, 199); font-weight: bold;"><span style="color: rgb(255, 255, 255);">Definition</span></th>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(212, 230, 241); font-weight: bold;">Bayesian Inference</td>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(212, 230, 241); font-weight: normal;">Bayesian is a process of using observed data to update prior beliefs. Typically parameters are assumed to be random variables arising from a distribution (e.g. rather than a discrete and solitary truth).</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(169, 204, 227); font-weight: bold;">Conditional auto-regressive (CAR)</td>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(169, 204, 227); font-weight: normal;">The CAR is a common prior for spatial disease mapping, particularly in a Bayesian framework. A CAR prior suggests that the value for a given area can be estimated CONDITIONAL ON the level of neighboring values.</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(212, 230, 241); font-weight: bold;">Frequentist Inference</td>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(212, 230, 241); font-weight: normal;">Inference in a frequentist framework draws conclusions from sample data by conceiving of this specific 'experiment' or sample as only one of thousands of possible experiments/samples, each capable of producing statistically independent results. Thus our inference is based on the probability of a given parameter (e.g. from one sample or experiment) arising in relation to all other (random) possibilities.</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(169, 204, 227); font-weight: bold;">Posterior</td>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(169, 204, 227); font-weight: normal;">In Bayesian inference, the 'posterior' is a formalized statement about the updated belief of the value of a parameter, conditional on the data (the likelihood) and the prior.</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 2pt 2pt 6pt; background-color: rgb(212, 230, 241); font-weight: bold;">Prior</td>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 1pt 1pt 1pt 1pt; border-top-color: rgb(255, 255, 255);  border-right-color: rgb(255, 255, 255);  border-bottom-color: rgb(255, 255, 255);  border-left-color: rgb(255, 255, 255); padding: 2pt 6pt 2pt 2pt; background-color: rgb(212, 230, 241); font-weight: normal;">In Bayesian inference, the 'prior' is a formalized statement of the probability of a parameter, as stated before we see the data.</td>
</tr>
</table></div>
</div>
</div>
<div id="spatial-thinking-in-epidemiology-4" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Spatial Thinking in Epidemiology<a class="anchor" aria-label="anchor" href="#spatial-thinking-in-epidemiology-4"><i class="fas fa-link"></i></a>
</h2>
<div id="what-is-bayesian-inference" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> What is <em>Bayesian Inference</em>?<a class="anchor" aria-label="anchor" href="#what-is-bayesian-inference"><i class="fas fa-link"></i></a>
</h3>
<p>In Disease Mapping I &amp; II we were introduced to global (aspatial) and local (spatial) Empirical Bayes estimation. In those modules, you were introduced to Bayes Theorem, and to a very high-level idea of the importance of the <em>prior</em>, <em>likelihood</em>, and <em>posterior</em> in Bayesian inference.</p>
<p>However we (intentionally) skirted over much detail in those sections. In this section we go only a little bit deeper; to be clear there is a lot more to know and learn about Bayesian inference than what is presented here. But hopefully this summary helps motivate the use of fully Bayesian analysis in spatial epidemiology.</p>
<div id="frequentist-versus-bayesian-inference" class="section level4" number="6.2.1.1">
<h4>
<span class="header-section-number">6.2.1.1</span> Frequentist versus Bayesian Inference<a class="anchor" aria-label="anchor" href="#frequentist-versus-bayesian-inference"><i class="fas fa-link"></i></a>
</h4>
<p><em>Frequentist statistics</em> and inference are probably what you have learned as ‘<em>statistics</em>’ up until now. In other words, it is typical that Bayesian inference is not taught in depth, or even at all, in many statistics courses. There is an interesting history for the current dominance of frequentist inference that is as much about personalities, egos, and power as it is about utility. But that’s for another day.</p>
<p>The core idea of frequentist inference centers on a mental model premised on comparing the data that is observed to abstract thought experiment of what would be expected under infinite repetitions. This strategy developed out of agricultural trials and survey sampling; in other words in settings where it was meaningful to think about either repetitively resampling a finite subset from a large population, or repetitively conducting an experiment in order to conceive of how a parameter might be expected to vary simply due to random error.</p>
<p><em>Bayesian inference</em> refers to an alternate philosophical and statistical approach to the analysis and inference of observed data. Instead of assuming there is a frequency of how often something <em>should</em> happen (e.g. in the abstract empirical thought experiment), Bayesian inference combines the mental models.</p>
<p>Bayesian’s articulate a statement about the plausible distribution of a parameter given past experience or knowledge (e.g. the <em>prior</em>), and then combine it directly with what the data actually suggest. The result of this combination is an updated statement about the distribution of the parameter (e.g. the <em>posterior</em>).</p>
<p>A common critique of Bayesian inference is that <em>priors</em> introduce subjective information as compared to the objective assumptions of frequentist inference. Instead, Bayesian priors are simply explicit and transparent about the assumptions being made; this is in contrast to the unrealistic or unstated assumptions required for frequentist inference.</p>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-3"></span>
<img src="images/frequentists_vs_bayesians.png" alt="Frequentist vs. Bayesian Inference"><p class="caption">
FIGURE 2.1: Frequentist vs. Bayesian Inference
</p>
</div>
<p>In the cartoon above there is a truth about the universe (e.g. the sun exploded: true or false) that is measured by the neurino detector. The measurement almost always reports the truth of it’s measurement, but when it rolls a double-six on dice, it lies to you. The measure occurs, the dice are rolled and the answer is “<em>the sun exploded</em>”.</p>
<p>The frequentist statistician on the left, finds that because the probability of telling a lie is so small, and given the answer was “<em>the sun exploded</em>”, then the sun must have exploded (e.g. the null is rejected). The Bayesian statistician on the right is more skeptical.</p>
<p>This is an exaggerated example of the role of <em>prior belief</em>. In a strictly frequentist interpretation, all that matters is the probability of the observed data under the hypothetical range of possibilities under the stated null.</p>
<div class="rmdnote">
<p>Obviously this is a silly cartoon. There is an interesting discussion of why the joke might also be based on an incorrect interpretation of frequentist statistics at <a href="https://statmodeling.stat.columbia.edu/2012/11/10/16808/">this link</a>.</p>
<p>One nuance that is brushed aside by the over simplified cartoon is that in frequentist terms, this is a joint hypothesis. Instead of the implied single hypothesis, “<em>what is the probability the sun exploded?</em>”, which is illustrated is the dual hypothesis, “<em>what is the probability the sun exploded AND the neurino detector told a lie?</em>”. So there is a clear way to make the logical flaw in thinking that is illustrated fit well in a frequentist as well as Bayesian framework.</p>
</div>
</div>
</div>
<div id="bayesian-inference-in-spatial-epidemiology" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> Bayesian inference in spatial epidemiology<a class="anchor" aria-label="anchor" href="#bayesian-inference-in-spatial-epidemiology"><i class="fas fa-link"></i></a>
</h3>
<p>While Bayesian statistics are widely incorporated into statistical methods across disciplines, Disease Mapping is perhaps the most ubiquitous use of Bayesian inference in epidemiology. Aside from the appealing flexibility of Bayesian inference generally, there are two specific reasons Bayesian inference <em>makes sense</em> for disease mapping:</p>
<ol style="list-style-type: decimal">
<li>
<em>Borrowing statistical strength</em> from spatial (and even spatio-temporal) neighbors, is an efficient way to improve the reliability and precision of small area disease rate estimates. You have already seen this with spatial Empirical Bayes estimation, and in a different way with Kernel Density Estimation. Leveraging the notion that <em>near things tend to be more alike than far thing</em>, the incorporation of spatial neighbors as a source of <strong>prior</strong> information can reduce variance of estimates, and smooth or shrink implausible and extreme values.</li>
<li>
<em>Modeling spatial auto correlation</em> explicitly is important because our statistics conventionally rely on assumptions of independence among observations. Therefore, if the disease rates in two adjacent counties are correlated because of shared environment, demographic structure, or interaction, this <em>dependence</em> can result in biased parameter estimates. <em>Empirical Bayes smoothing did not explicitly address this</em>, but fully Bayesian models with spatial priors can explicitly model the auto correlation, thus allowing estimation of the likelihood under assumptions of <em>conditional independence</em>.</li>
</ol>
<p>Bayesian statistics are not inherently any more complex than frequentists statistics. However, you have likely had substantially more opportunity to assimilate ideas in frequentist thinking, and thus Bayesian statistics may feel quite foreign. There are two concepts that we will incorporate into disease mapping in a Bayesian framework: <em>hierarchical models</em> and the (conditional autoregressive (CAR)) prior.</p>
<div id="bayesian-hierarchical-models" class="section level4" number="6.2.2.1">
<h4>
<span class="header-section-number">6.2.2.1</span> Bayesian hierarchical models<a class="anchor" aria-label="anchor" href="#bayesian-hierarchical-models"><i class="fas fa-link"></i></a>
</h4>
<p>Bayesian models are <em>hierarchical</em> in the sense that we conceive of parameters not as discrete point estimates, but instead as a range of plausible values described by a probability distribution function (PDF). Thus the target distribution of parameters might be a <em>lower-level</em> of the hierarchy, while the parameters of a given PDF (e.g. the <em>mean</em> or <em>variance</em>), are themselves assumed to arise from a random probability distribution, representing another hierarchical level.</p>
<p>Thus, to describe the probability of random variables at the lowest level (e.g. perhaps the <em>excess relative risk</em> of disease in <span class="math inline">\(region_i\)</span> as compared to expected), we need to specify a “<em>second level</em>”, and then possibly a <em>third level</em> in a hierarchical fashion.</p>
<p>Take for example our interest in disease mapping in characterizing spatial heterogeneity, and specifically the value of the region-specific excess relative risk as an indicator of deviation from expectation.</p>
<p>In previous settings we have notated the <em>likelihood</em> of the excess relative risk as <span class="math inline">\(\theta_i\)</span>; here we will examine <span class="math inline">\(\theta_i\)</span> on the log scale, defining a related parameter <span class="math inline">\(\psi\)</span> (spelled <em>psi</em> and pronounced like <em>sigh</em>): <span class="math inline">\(\psi_i = log(\theta_i)\)</span>. Therefore the following two statements about our observed data, <span class="math inline">\(Y_i\)</span> and our probability model say the same thing:</p>
<p><span class="math display">\[Y_i | \beta, \psi_i \sim Poisson(E_i exp(x_i \beta + \psi_i))\]</span>
<span class="math display">\[Y_i| \theta_i \sim Poisson(E_i \theta_i)\]</span>
The only difference in those two likelihood statements is that:</p>
<ul>
<li>
<strong>a)</strong> the first is on the log scale whereas the second is not;<br>
</li>
<li>
<strong>b)</strong> the first explicitly incorporates possible covariates with resulting parameters, <span class="math inline">\(\beta\)</span>.</li>
</ul>
<p>Importantly, each time we use one of those Greek letters, we are saying it represents a <em>random variable</em>. Therefore, in a Bayesian framework, we must specify the distribution and parameters of each random variable. These distributional specifications are the <em>prior</em>!</p>
<p>They differ from the prior in <em>Empirical Bayes</em> because we specify them as full probability distributions, rather than as discrete values calculated from the observed (<em>empirical</em>) data. This is where the model becomes <em>hierarchical</em>. In the first equation above there are two random variables: <span class="math inline">\(\beta_i\)</span> and <span class="math inline">\(\psi_i\)</span>. Each requires a specification of a prior.</p>
<p><span class="math display">\[\beta \sim N(0,100000)\]</span>
In this particular example, I have specified the prior on the <span class="math inline">\(\beta\)</span> (e.g. the prior for the range of plausible coefficients for any possible included covariates in our model, such as rural/urban or population density) to be relatively <em>uninformative</em>.</p>
<p>In other words, by saying that <span class="math inline">\(\beta\)</span> arises from a <em>normal distribution</em> with mean of zero (e.g. on average I expect there is no association) and a variance of 100,000, I am saying that there is very little specific prior information; therefore the data (e.g. the likelihood) will win out in all cases. This is a common practice for <em>fixed effects</em> (e.g. global summary or stationary parameters that are not assumed to vary over space), and is quite similar to the frequentist assumption that anything is possible.</p>
<p>However, the strategy for the prior on <span class="math inline">\(\psi_i\)</span> is a little different. Recall, when discussing global and local (aspatial and spatial) Empirical Bayes, that the chief distinction was in the specification of the prior: in <em>global/aspatial</em> there was a single prior expectation for the entire study region, whereas for <em>local/spatial</em> EB, there was a unique prior for each region, defined in part by values in neighboring regions.</p>
<p>A similar approach could be taken in fully Bayesian disease modeling. One approach would be to define a single prior that applies to each region, irrespective of their spatial relatedness to one another. This is often called a <em>spatially unstructured</em> random effect. In other words it is a random variable that is not defined by spatial connectivity, but instead arises from some non-spatial phenomenon. Instead of being <em>uninformative</em>, we will incorporate <em>prior knowledge</em> in the form of information about the plausible range of values across the study region.</p>
<p><span class="math display">\[\psi_i \sim N(0,\sigma^2)\]</span></p>
<p>This says that the range of possible values of <span class="math inline">\(\psi\)</span> arise from a normal distribution, centered on zero (e.g. on expectation each region is exactly as expected), with a variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>As mentioned above, in the Empirical Bayes, the value of this variance term (e.g. the specification of how different we think regions can plausibly be from one another) was specified using the empirical or observed data. However, in the hierarchical Bayesian setting, we can go yet another level and say that even <span class="math inline">\(\sigma^2\)</span> is a random variable with a prior of its own. For example a common prior for a variance term (a prior for a prior is called a <em>hyperprior</em>!) is:</p>
<p><span class="math display">\[\sigma^2 \sim inverse-gamma(1, 0.01)\]</span>
The inverse gamma distribution is specified by two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Theoretically we could specify yet another hyper prior for these two parameters, but in this example –and following convention–I specify numeric values of 1 and 0.01. Here is an example of what this prior distribution looks like (recall <span class="math inline">\(\sigma^2\)</span> describes variance on the log scale):</p>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-4-1.png" width="672"></div>
<p>This summary of <em>hierarchical Bayesian</em> models has not explicitly incorporated <em>spatial relatededness</em> and neighbors. The next section introduces a <em>spatial prior</em>.</p>
</div>
<div id="conditional-auto-regressive-priors" class="section level4" number="6.2.2.2">
<h4>
<span class="header-section-number">6.2.2.2</span> Conditional auto-regressive priors<a class="anchor" aria-label="anchor" href="#conditional-auto-regressive-priors"><i class="fas fa-link"></i></a>
</h4>
<p>As mentioned in the previous section, just as there were both <em>global</em> and <em>local</em> priors for Empirical Bayes, so there are for fully Bayesian disease mapping. The <em>global</em> prior for <span class="math inline">\(\psi_i\)</span> was described above as arising from a common or shared normal distribution for all regions.</p>
<p>This helps address the concern for instability of estimates due to sparse data in a single region, by shrinking or smoothing local regions towards a global distribution. However, this strategy does not address the the ubiquitous presence of spatial-dependence. In other words the global strategy neither addresses the violation of assumption of independence among regions (e.g. they are often actually quite dependent or auto-correlated!), nor does it take advantage of that fact to provide stronger priors.</p>
<p>The <em>Conditional Auto Regressive (CAR)</em> model is commonly used in both frequentist and Bayesian spatial statistics. In particular, it informs the estimation of each local log-relative risk parameter, <span class="math inline">\(\psi_i\)</span> by conditioning on information in the neighbors. The CAR model is a setup in which data are assumed to be distributed <em>normally</em> (e.g. Gaussian), with the mean and variance defined <em>conditional on neighbors</em>. In the fully Bayesian framework, we can use this CAR conditioning to parameterize (e.g. as a <em>prior for</em>) the values of local <span class="math inline">\(\psi_i\)</span>.</p>
<p>The CAR model is incorporated into multiple different types of Bayesian priors in disease mapping. The basic setup for the CAR model is described here:</p>
<p><span class="math display">\[\psi_i|\psi_{j \neq i} \sim N\left(\frac{\sum_{j \neq i} w_{ij}\psi_i}{\sum_{j \neq i}w_{ij}}, \frac{1}{\tau_{CAR}\sum_{j \neq i}w_{ij}}\right)\]</span></p>
<p>This says that the values of <span class="math inline">\(\psi_i\)</span> (e.g. the local log-relative excess risk) are normally distributed, conditional on the values of <span class="math inline">\(\psi_i\)</span> in neighbors of <span class="math inline">\(i\)</span>. The mean of the region-specific normal distribution is a weighted average of the values of <span class="math inline">\(\psi_i\)</span> for all neighbors, and the variance of the distribution is informed by <span class="math inline">\(\tau_{CAR}\)</span>, a hyperprior denoting the conditional variance among the neighbors. The term <span class="math inline">\(w_{ij}\)</span> is a binary spatial weights matrix created much as did for spatial Empirical Bayes by identifying neighboring or adjacent units <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> as <span class="math inline">\(w_{ij}=1\)</span> and all non-adjacent or non-neighbor pairs <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> as <span class="math inline">\(w_{ij}=0\)</span></p>
<p>A very commonly used spatial prior in Bayesian disease mapping is called the Besag-Yorke-Mollie or BYM prior. It combines the spatially-explicit CAR prior above to characterize the parts of spatial heterogeneity that are <em>spatially structured</em> (e.g. related to spatial dependence in the data), along with the global or <em>spatially unstructured</em> Gaussian prior described in the previous section.</p>
<p>The idea is that some sources of variation between regions are in fact spatially dependent (e.g. through diffusion, selection of similar populations, common exposure, etc), whereas other sources of difference <em>are not spatially dependent</em> (e.g. could be abrupt changes between rural-suburban-urban, or might be region-specific exposures that are not shared with neighbors). This combination of types of prior are sometimes called <em>convolution priors</em> because they combine two separate random effects together.</p>
<p>We can describe the fully hierarchical Bayesian BYM model like this:</p>
<p><span class="math display">\[Y_i|\beta, \psi_i \sim Poisson(E_i, exp(\beta, \psi_i))\]</span>
Because we are now specifying that the local values of <span class="math inline">\(\psi_i\)</span> are contributed to by two distinct random components (e.g. one <em>spatially structured</em> and one <em>unstructured</em>), we can define <span class="math inline">\(psi_i\)</span> as the sum of two parts: <span class="math inline">\(\psi_i = u_i + v_i\)</span>, where <span class="math inline">\(u_i\)</span> is the spatially structured random variable and <span class="math inline">\(v_i\)</span> is the unstructured random variable. Each of these therefore needs a prior:</p>
<p><span class="math display">\[u_i|u_{j \neq i} \sim N\left(\frac{\sum_{j \neq i} w_{ij}u_i}{\sum_{j \neq i}w_{ij}}, \frac{1}{\tau_{CAR}\sum_{j \neq i}w_{ij}}\right)\]</span>
<span class="math display">\[v_i \sim N(0,\sigma^2)\]</span></p>
<p>Finally, we need to specify <em>hyperpriors</em> for the two variance terms, <span class="math inline">\(\tau_{CAR}\)</span>, and <span class="math inline">\(\sigma^2\)</span>; these can be defined in a relatively non-informative manner using <em>Gamma</em> or <em>Inverse Gamma distributions</em> to allow for a wide range of possibilities.</p>
<p>Other specification of the Bayesian disease mapping priors using the CAR model can be seen in the additional resources cited at the beginning of this section.</p>
<div class="rmdcaution">
<p>Somewhat confusingly, the <code>CARBayes</code> package described below uses slightly different Greek letter nomenclature. Specifically, the package authors use <span class="math inline">\(\psi\)</span> to indicate the <em>spatially-correlated</em> or structure random effects, but describes the set of random effects (e.g. as in a convolution model where there are both spatially structured and unstructured random effects)–of which <span class="math inline">\(\psi\)</span> is one component–with the Greek letter <span class="math inline">\(\phi\)</span> (spelled <em>phi</em> and pronounced like <em>figh</em>).</p>
<p>In some other models in the <code>CARBayes</code> package, there are both <em>spatially-correlated</em> and <em>spatially unstructured</em> random effects, but in the Leroux, <span class="math inline">\(\psi_i\)</span> = <span class="math inline">\(\phi_i\)</span>. I point this out because the model output will have a matrix named <em>phi</em>, which might seem confusing if we were calling that thing psi (<span class="math inline">\(\psi\)</span>).</p>
</div>
</div>
<div id="making-inference-from-bayesian-models" class="section level4" number="6.2.2.3">
<h4>
<span class="header-section-number">6.2.2.3</span> Making inference from Bayesian Models<a class="anchor" aria-label="anchor" href="#making-inference-from-bayesian-models"><i class="fas fa-link"></i></a>
</h4>
<p>While the basic logic of Bayesian inference is relatively straightforward, as you can see the Bayesian hierarchical framework looks complex! In very simple settings it is possible to calculate the full posterior distribution (e.g. the combination of the likelihood and the prior via Bayes Theorem) using closed form strategies.</p>
<p>However it is common that no closed-form solution exists for these more complex, hierarchical and conditional models. Therefore, there are currently two analytic strategies used to make inference when a simple formula doesn’t work.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Markov Chain Monte Carlo (MCMC)</strong> simulation has been used for decades in Bayesian analysis. This ‘<em>brute force</em>’ method takes advantage of two statistical tools to make inference about the shape of the posterior distribution of even very complex Bayesian models.</li>
</ol>
<ul>
<li>
<em>Markov Chain</em> is an algorithm for drawing from (possibly highly dimensional) parameter space. It uses stochasticity (randomness) to ‘check’ different possible parts of the parameter space, using only a comparison of how well the current location fits as compared to the previous. As a result the algorithm can ‘learn’ without getting stuck in one location. The goal is to eventually (through random sampling plus learning) settle on the most likely answer or parameter value.</li>
<li>
<em>Monte Carlo</em> simulations are a repetitive sampling or drawing from the posterior. While we cannot describe exactly the shape of the posterior distribution, if we take a very large number of samples from that distribution (e.g. from the Markov Chain) we can create a summary of the shape of the posterior. So for instance, the mean or median of a large number of samples becomes our parameter point estimate, and the <span class="math inline">\(2.5^{th}\)</span> and <span class="math inline">\(97.5^{th}\)</span> percentiles of the samples become <em>Bayesian Credible Intervals</em>.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Integrated Nested Laplace Approximation (INLA)</strong>. This is a much newer strategy that aims to provide a more efficient way to <em>approximate</em> the shape and scale of the posterior. INLA works in <code>R</code> and is especially well suited to complex hierarchical, spatial, and spatio-temporal models of areal or point data.</li>
</ol>
</div>
</div>
</div>
<div id="spatial-analysis-in-epidemiology-4" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Spatial Analysis in Epidemiology<a class="anchor" aria-label="anchor" href="#spatial-analysis-in-epidemiology-4"><i class="fas fa-link"></i></a>
</h2>
<p>Bayesian analysis requires a bit more care and caution on the part of the analyst. I strongly recommend proceeding on any project with great caution (and ideally with an expert consultant!). However, there are some tools which have made Bayesian modeling more accessible, in part by pre-programming some ‘<em>sensible</em>’ defaults into functions.</p>
<p>In this module, we only discuss the MCMC methods as implemented in a single package, <code>CARBayes</code>, because this package represents a reasonable point-of-entry for those interested in starting down the Bayesian path. However there are excellent tutorial resources for learning INLA, and many other Bayesian tools as well.</p>
<p>The <code>CARBayes</code> package has functions for fitting a wide range of spatial disease mapping models including:</p>
<ul>
<li>
<em>Besag-York-Mollie</em> (BYM) described above, in which spatial heterogeneity is modeled as the sum of two random processes: a spatially structured process with a spatial CAR prior; and a spatially independent or unstructured process</li>
<li>
<em>Leroux CAR model</em> is an extension of CAR where there is a single random effect (e.g. not two as in BYM), but there is a variable degree of spatial autocorrelation parameterized with a random hyperprior, <span class="math inline">\(\rho\)</span> that describes how some places might have more versus less spatial dependence.</li>
<li>
<em>Dissimilarity model</em> uses a CAR prior to identify boundaries where risk or rate abruptly changes. This model therefore highlights distinct differences amongst neighbors as opposed to encouraging similarity; as such it can be useful for identifying spatial clustering.</li>
<li>
<em>Localised CAR model</em> is another extension similar to the dissimilarity model that aims to identify abrupt changes in the surface and highlight clusters.</li>
<li>
<em>Multilevel CAR models</em> are a nice alternative when you have access to individual level outcomes nested within areal (ecologic) units, as opposed to only relying on counts aggregated to those units.</li>
<li>
<em>Multivariate Leroux model</em> is distinct from all of the preceding models which are <em>univariate</em>, meaning there is a single ‘<em>outcome</em>’ for each unit of observation. In <em>multivariate</em> analysis (which is distinct from the more common <em>multivariable</em> analysis such as multiple regression), there are multiple correlated outcomes for each unit of analysis. One example is modeling the incidence of three kinds of cancer simultaneously.</li>
</ul>
<p>Each of these models can be fit with Poisson, Binomial, Normal (Gaussian), or Multinomial distributed data.</p>
<p>The <a href="https://cran.r-project.org/web/packages/CARBayes/vignettes/CARBayes.pdf"><code>CARBayes</code> package vignette</a> provides additional detail on the specification of these different models, and examples of fitting each using the built-in functions. In addition, there is a sister package, <code>CARBayesST</code> that has extensions for spatio-temporal data, where the same regions are observed not once but multiple times. More information about this package is available in the <a href="https://cran.r-project.org/web/packages/CARBayesST/vignettes/CARBayesST.pdf"><code>CARBayesST</code> vignette</a></p>
<p>The example below uses the commonly implemented <em>Besag-York-Mollie</em> (BYM) model.</p>
<div id="packages-data" class="section level3" number="6.3.1">
<h3>
<span class="header-section-number">6.3.1</span> Packages &amp; Data<a class="anchor" aria-label="anchor" href="#packages-data"><i class="fas fa-link"></i></a>
</h3>
<p>In addition to the now-familiar packages, you will also need to load the <code>CARBayes</code> package.</p>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-spatial.github.io/sf/">sf</a></span><span class="op">)</span>        <span class="co"># sf provides st_read for importing</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/r-spatial/spdep/">spdep</a></span><span class="op">)</span>     <span class="co"># spdep has functions for creating spatial neighbor objects</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-tmap.github.io/tmap/">tmap</a></span><span class="op">)</span>      <span class="co"># tmap for plotting results</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>     <span class="co"># dplyr for pipe processing of data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/duncanplee/CARBayes">CARBayes</a></span><span class="op">)</span>  <span class="co"># CARBayes has functions for fitting a range of CAR models</span></span></code></pre></div>
<p>This example will continue to use the <em>very low birthweight</em> data used in previous parts of the eBook. The following code reads it in as <code>sf</code> and calculates a <em>raw rate</em> of VLBW to use for subsequent comparisons.</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vlbw</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_read.html">st_read</a></span><span class="op">(</span><span class="st">'ga-vlbw.gpkg'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>rate <span class="op">=</span> <span class="va">VLBW</span> <span class="op">/</span> <span class="va">TOT</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">$</span><span class="va">VLBW</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">$</span><span class="va">TOT</span><span class="op">)</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">expected</span> <span class="op">&lt;-</span> <span class="va">r</span><span class="op">*</span><span class="va">vlbw</span><span class="op">$</span><span class="va">TOT</span></span></code></pre></div>
</div>
<div id="preparing-for-carbayes" class="section level3" number="6.3.2">
<h3>
<span class="header-section-number">6.3.2</span> Preparing for <code>CARBayes()</code><a class="anchor" aria-label="anchor" href="#preparing-for-carbayes"><i class="fas fa-link"></i></a>
</h3>
<p>In addition to the usual preparation of an analytic data set, the primary concern before fitting the Bayesian CAR model is creation of the weights matrix, <code>W</code>, that serves to identify the set of <em>neighbors</em> each county has to serve as inputs for describing the shape of the <em>prior probability distribution</em>. We can use all of the same tools from previous weeks for creating a range of neighbor objects, with the following caveats:</p>
<ol style="list-style-type: decimal">
<li>Neighbors (and weights) must be <em>symmetric</em>, which means that if <span class="math inline">\(region_i\)</span> is a neighbor to <span class="math inline">\(region_j\)</span>, then <span class="math inline">\(region_j\)</span> is also a neighbor to <span class="math inline">\(region_i\)</span>. Contiguity and graph-based neighbor objects are symmetric by design, but k-nearest neighbors are often <em>asymmetric</em>. Thus, if you created a k-nearest neighbors object you may need to <em>force symmetry</em> by using the function <code><a href="https://r-spatial.github.io/spdep/reference/testnb.html">make.sym.nb()</a></code>.</li>
<li>All regions <strong>must</strong> have at least one neighbor. More formally, the sum of all rows in the weights matrix must be at least 1. If the neighbor approach results in unlinked regions (areas with zero neighbors, as could be the case with islands), they need to be excluded, or an alternate or adapted weights matrix created.</li>
<li>The object we will use in the <code>CARBayes</code> function below must be a literal <em>weights matrix</em> (e.g. <span class="math inline">\(159 \times 159\)</span>) and not just the <code>nb</code> object.</li>
</ol>
<p>Below I create a simple Queen contiguity neighbor object, and then convert that object to a weights matrix. The use of <code>style = 'B'</code> in the creation of the weights matrix says that the values in the resulting matrix should be <em>binary</em> (0 or 1). The default (<code>style = 'W'</code>) results in <em>row-standardized</em> weights, which are useful for other analytic tasks, but not necessary in the CAR models, because the CAR prior inherently adjusts for the number of neighbors.</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">qnb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r-spatial.github.io/spdep/reference/poly2nb.html">poly2nb</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">)</span></span>
<span><span class="va">qnb_mat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r-spatial.github.io/spdep/reference/nb2mat.html">nb2mat</a></span><span class="op">(</span><span class="va">qnb</span>, style <span class="op">=</span> <span class="st">'B'</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">qnb_mat</span><span class="op">)</span>  <span class="co"># confirming the dimensions of the matrix</span></span></code></pre></div>
<pre><code>## [1] 159 159</code></pre>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">qnb_mat</span><span class="op">)</span> <span class="co"># confirming its class</span></span></code></pre></div>
<pre><code>## [1] "matrix" "array"</code></pre>
<div class="rmdcaution">
<p><strong>Make sure your weights match your final data!</strong></p>
<p>It is always important that your spatial neighbors or weights objects are made from your <em>final dataset</em>! Any changes (additions or deletion of rows, but also any re-sorting or rearranging) will result in <em>misalignment between the spatial weights matrix and the data</em>.</p>
</div>
<div id="how-many-monte-carlo-samples-are-needed" class="section level4" number="6.3.2.1">
<h4>
<span class="header-section-number">6.3.2.1</span> How many Monte Carlo Samples are needed?<a class="anchor" aria-label="anchor" href="#how-many-monte-carlo-samples-are-needed"><i class="fas fa-link"></i></a>
</h4>
<p>This depends on how complex the model is, and how strong the signal in the data is. But in general a few concepts are worth mentioning.</p>
<ol style="list-style-type: decimal">
<li>First, there is a tendency for the (randomly selected) starting location of a Markov Chain to influence the early samples. For this reason it is common to plan to discard a portion of the samples during a <em>burn-in</em> period. This essentially means that we hope there is no dependence on initial conditions after removing the first <span class="math inline">\(n\)</span> samples. This burn-in can be quite large, e.g. tens of thousands of samples!</li>
<li>Our goal is that <em>model convergence</em> is achieved, meaning that the Markov Chain has ‘<em>learned</em>’ enough to settle down into a relatively consistent area in the parameter space. This can take many thousands of samples, and thus convergence diagnostics are often used to guide decisions about how many samples are required.</li>
<li>At the end of the day, we only need about <span class="math inline">\(n=1000\)</span> reliable and high quality samples from the posterior to accurately describe it. But it may take <span class="math inline">\(10,000\)</span>, <span class="math inline">\(50,000\)</span> or even <span class="math inline">\(100,000\)</span> or more samples to achieve the preceding goals of burn-in and convergence. One option would be to just keep the last <span class="math inline">\(1,000\)</span> samples. But a preferable option is to use <em>thinning</em> to sample every <span class="math inline">\(10^{th}\)</span> or every <span class="math inline">\(100^{th}\)</span> sample, after the burn-in period. This achives two goals: it requires less memory to store all of the samples, but it also reduces any residual auto-correlation among sequential samples.</li>
</ol>
</div>
</div>
<div id="fitting-a-besag-york-mollie-bym-bayesian-model" class="section level3" number="6.3.3">
<h3>
<span class="header-section-number">6.3.3</span> Fitting a <em>Besag-York-Mollie (BYM)</em> Bayesian model<a class="anchor" aria-label="anchor" href="#fitting-a-besag-york-mollie-bym-bayesian-model"><i class="fas fa-link"></i></a>
</h3>
<p>Before fitting the model, it is convenient (but not required) to specify the <em>fixed-effect</em> component of the model. This is where you specify the outcome and the predictors. CAR Bayesian models can incorporate covariates as categorical, continuous, or even non-linear (e.g. spline or polynomials) in the likelihood. There are two reasons you might choose to include covariates:</p>
<ol style="list-style-type: decimal">
<li>Covariates that are strongly predictive of the outcome will improve the prediction of local fitted rates. One interpretation of the <em>random effects</em> (e.g. <span class="math inline">\(\psi_i\)</span>), is that they represent unmeasured causes or correlates of the outcome. Addition of relevant covariates could <em>explain</em> some of the previously-unmeasured factors.</li>
<li>A second reason is that there may be interest in describing geographic trends in disease <em>conditional on</em> a covariate. The example we have used previously is local age structure, although other covariates might be a nuisance in interpreting geographic patterns of disease.</li>
</ol>
<p>For now, we do not have any covariates, so the only thing in the <em>fixed-effect</em> portion of the model is specification of the outcome variable (count of deaths) and the offset variable (log of denominator at risk for death), which is necessary for the Poisson model of counts from regions with different populations at risk. Note that all we are creating here is a <em>formula object</em>. It is not doing anything other than naming our formula.</p>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="va">VLBW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">TOT</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now we have the three main ingredients:</p>
<ol style="list-style-type: decimal">
<li>Data, in the form of the <code>vlbw</code> object</li>
<li>The spatial weights matrix, <code>W</code>, which represents the spatial relationships (<code>qnb_mat</code>)</li>
<li>The fixed effects portion of the model.</li>
</ol>
<p>To call the BYM model we specify:</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bym</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/CARBayes/man/S.CARbym.html">S.CARbym</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">mod</span>, </span>
<span>                        family <span class="op">=</span> <span class="st">'poisson'</span>, </span>
<span>                        data <span class="op">=</span> <span class="va">vlbw</span>, </span>
<span>                        W <span class="op">=</span> <span class="va">qnb_mat</span>,</span>
<span>                        burnin <span class="op">=</span> <span class="fl">30000</span>, </span>
<span>                        n.sample <span class="op">=</span> <span class="fl">60000</span>, </span>
<span>                        thin <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                        verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="rmdnote">
<p><strong>Poisson or Poisson-Gamma?</strong></p>
<p>Notice that the <code>family = 'poisson'</code>, even though in previous work we observed that there may be extra-Poisson variation in these data. That led us to prefer a Poisson-Gamma probability model (or a negative binomial); so why not choose that here?</p>
<p>In part because in the fully Bayesian CAR model we actually <strong>are</strong> allowing for extra-Poisson variation with the conditional prior, which itself has a Gamma prior on the variance.</p>
</div>
<p>The <code>formula</code>, <code>family</code>, <code>data</code>, and <code>W</code> have been discussed. But the next three arguments require some explanation.</p>
<ul>
<li>
<code>burnin = 30000</code> specifies how many of the MCMC samples should be discarded. In general, discarding a large number in the beginning via the <code>burnin</code> argument is recommended to reduce sensitivity to initial conditions and ignore the time spent early in the Markov Chain process.</li>
<li>
<code>n.sample = 60000</code> specifies the total number of samples to draw. Obviously this number must be larger than the <code>burnin</code> or else there will be nothing left to look at! In this case we take 60,000 samples, discarding the first 30,000, leaving 30,000 for examination.</li>
<li>
<code>thin = 30</code> says to only <em>keep</em> every 30th sample drawn. The reasons for thinning are to reduce auto correlation among consecutive values, and to save memory, by only keeping a useful number of samples to describe the posterior. We are keeping 1000 samples, which is adequate for summarizing the parameters of interest.</li>
</ul>
<p>There are actually many more options the analyst can choose for specifying the BYM model. For instance, I mentioned that an appealing feature of the <code>CARBayes</code> package is that it has <em>built-in</em> a number of sensible defaults for models, so that the analyst doesn’t have to make so many decisions.</p>
<p>However, those defaults can be changed. For example, the inverse gamma prior on the variance, <span class="math inline">\(\tau^2\)</span>, has default settings, but these can be modified with additional arguments. While you might not be able to digest them all now, it might be useful to look briefly at the help documentation for <code>S.CARbym</code>.</p>
</div>
<div id="summarizing-carbayes-model-output" class="section level3" number="6.3.4">
<h3>
<span class="header-section-number">6.3.4</span> Summarizing <code>CARBayes</code> model output<a class="anchor" aria-label="anchor" href="#summarizing-carbayes-model-output"><i class="fas fa-link"></i></a>
</h3>
<p>The <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function returns a list of the objects returned, but nothing more useful. The <code><a href="https://rdrr.io/r/base/print.html">print()</a></code> function provides a subset of model summary statistics.</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">bym</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">bym</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## #################
## #### Model fitted
## #################
## Likelihood model - Poisson (log link function) 
## Random effects model - BYM CAR
## Regression equation - VLBW ~ offset(log(TOT))
## 
## 
## #################
## #### MCMC details
## #################
## Total number of post burnin and thinned MCMC samples generated - 
## Number of MCMC chains used - 
## Length of the burnin period used for each chain - 
## Amount of thinning used - 
## 
## ############
## #### Results
## ############
## Posterior quantities and DIC
## 
##                Mean    2.5%   97.5% n.effective Geweke.diag
## (Intercept) -3.9946 -4.0465 -3.9434      1000.0        -0.8
## tau2         0.1156  0.0482  0.2135       278.9        -0.8
## sigma2       0.0093  0.0017  0.0275        77.9         0.2
## 
## DIC =  889.1872       p.d =  54.33981       LMPL =  -452.83</code></pre>
<p>Only a few of the total parameters estimated are summarized here. Specifically the <code><a href="https://rdrr.io/r/base/print.html">print()</a></code> function will display all of the <em>fixed-effects</em> (only the global intercept is included here because we did not specify any covariates), as well as the hyper priors, <span class="math inline">\(\tau^2\)</span> and <span class="math inline">\(\sigma^2\)</span>.</p>
<ul>
<li>The parameter <span class="math inline">\(\tau^2\)</span> characterizes the conditional variance of the <em>spatially structured</em> random effects (e.g. <span class="math inline">\(u_i\)</span> in the BYM convolution prior).</li>
<li>The parameter <span class="math inline">\(\sigma^2\)</span> characterizes the variance of the <em>unstructured</em> or global random effects.</li>
</ul>
<p>It is clear there is more variability in the <span class="math inline">\(\tau^2\)</span> than in the <span class="math inline">\(\sigma^2\)</span> suggesting that of the total variability in county-specific prevalence of VLBW, more of it seems to be attributable to spatially-structured processes as compared to unstructured processes.</p>
<div class="rmdcaution">
<p><strong>A note of caution</strong></p>
<p>Although it is appealing to interpret the two variance components in the BYM model as I just did (e.g. describing the proportionate contribution to total variation), it is also known that in BYM models in particular, these two cannot be clearly identified independent of one another. In other words together they can describe variation, but it is not safe to make inference on either separate from the other.</p>
<p>Instead we can be more confident that the sum of the two is a reliable prior.</p>
</div>
<p>Also evident in the results of the <code>print(bym)</code> results is that each of these hyper parameters, and the fixed-effects, are summarized as the <em>median</em> value from the posterior samples (e.g. n=1,000 retained posterior samples in our case), as well as the <span class="math inline">\(2.5^{th}\)</span> and <span class="math inline">\(97.5^{th}\)</span> percentiles of the posterior (e.g. the <em>Bayesian Credible Intervals</em>).</p>
<p>The Deviation Information Criteria (DIC) is a Bayesian model fit statistic, and like other fit statistics, <em>smaller is better</em>.</p>
<p>Finally, the <em>Geweke Diagnostic</em> test is designed to characterize how well the Markov Chain has converged on a stationary location in parameter space. The assumption with Markov Chain, is that the steps in the chain will move towards the optimum (best fitting) values, and once there will remain in that area. Thus the Geweke compares the mean value of the sampled posterior at the end of the samples, and at some earlier point.</p>
<p>If the model has converged, the two means will be similar. The resulting test statistic is a standard Z-score. Values between -1.96 and 1.96 are suggestive of <em>good convergence</em>, whereas values greater than 1.96, or less than -1.96, may not be converged.</p>
<p>In the above model with 60,000 total samples (and 30,000 burn-in), the Geweke diagnostic suggests good convergence for the intercept but perhaps poor convergence for the two variance hyperpriors. The model could be re-fit with more iterations to see if that improves convergence. Other approaches include better model-specification (e.g. perhaps important variables are missing, making the model non-identifiable).</p>
</div>
<div id="making-inference-from-bayesian-posteriors" class="section level3" number="6.3.5">
<h3>
<span class="header-section-number">6.3.5</span> Making inference from Bayesian posteriors<a class="anchor" aria-label="anchor" href="#making-inference-from-bayesian-posteriors"><i class="fas fa-link"></i></a>
</h3>
<p>The output of the <code><a href="https://rdrr.io/pkg/CARBayes/man/S.CARbym.html">S.CARbym()</a></code> model function is complex. If you use <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> or <code><a href="https://rdrr.io/r/base/names.html">names()</a></code> on the output object, you will see there are several components. The one called <em>samples</em> contains the posterior draws from the MCMC process. Within that object are several data matrices, each containing the posterior samples for different parameters. You can understand a little bit about them by looking at their <em>shape</em> or dimension with <code><a href="https://rdrr.io/r/base/dim.html">dim()</a></code>.</p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">bym</span><span class="op">)</span>          <span class="co"># what is inside the model output object?</span></span></code></pre></div>
<pre><code>##  [1] "summary.results"     "samples"             "fitted.values"      
##  [4] "residuals"           "modelfit"            "accept"             
##  [7] "localised.structure" "formula"             "model"              
## [10] "X"</code></pre>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">)</span>  <span class="co"># what is inside the 'samples' sub-object?</span></span></code></pre></div>
<pre><code>## [1] "beta"   "psi"    "tau2"   "sigma2" "fitted" "Y"</code></pre>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span> <span class="co"># 1000 draws for 1 beta fixed effect (the intercept)</span></span></code></pre></div>
<pre><code>## [1] 1000    1</code></pre>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">psi</span><span class="op">)</span>  <span class="co"># 1000 draws for the psi = ui + vi for each of 159 counties</span></span></code></pre></div>
<pre><code>## [1] 1000  159</code></pre>
<p>One of the matrices inside the <code>bym</code> object is named <code>fitted.values</code>. This could be of interest if, instead of characterizing the heterogeneity in <span class="math inline">\(\psi_i\)</span> (e.g. the log-relative risk), you wish to map the model-fitted <em>rates</em>.</p>
<p>Fitted values are on the scale of the observed data. That means that in the case of a Poisson model, the fitted values are <em>counts</em> of VLBW as predicted by the model. As we will see below, these counts divided by the known denominator (total birth count) will produce a model-predicted <em>risk</em> or <em>prevalence</em>.</p>
<p>However, if we want to know more about the posterior of specific random variables, such as <span class="math inline">\(\beta\)</span> we should look at <code>bym$samples$beta</code>; if we want to know about the random effects <span class="math inline">\(\psi_i\)</span>, we should look at <code>bym$samples$psi</code>.</p>
<p>One thing you might like to do is examine the Markov Chain trace plot to understand how it sampled the parameter space through sequential steps. This is useful as an indicator of convergence (e.g. if the trace plot has <em>settled</em> into a common range, it has likely converged, whereas if it wanders all over the place, it has not).</p>
<p>Another visualization that can be useful is to see the shape of the sampled posterior probability distribution. The package <code>coda</code> is designed specifically for working with MCMC samples from Bayesian models of all kinds, and has some functions for creating these plots. Below are two functions for visualizing the posterior estimates of the global intercept, <span class="math inline">\(\beta\)</span>.</p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">coda</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-14-1.png" width="672"></div>
<p>On the y-axis is the sampled values from the posterior distribution for <span class="math inline">\(\beta\)</span>, and the x-axis is each of the 1,000 samples we retained (e.g. 60,000 draws - 30,000 burnin, with thinning). Notice how the <code><a href="https://rdrr.io/pkg/coda/man/traceplot.html">traceplot()</a></code> shows the Markov Chain moving around to test different values. While there is a lot of variation, the bulk of the samples are are centered in a relatively narrow range, from <span class="math inline">\(-4.02\)</span> to <span class="math inline">\(-3.96\)</span>, suggesting good convergence.</p>
<p>Also notice how the chain has ‘leaps’ or forays <em>away</em> from the central area of parameter space or values. That is another feature of Markov Chain: it will randomly evaluate other parts of the parameter space to see if they might fit better than the current. The fact that the plot always returns quickly to the same place suggests a rejection of the alternate values.</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">coda</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/densplot.html">densplot</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-15-1.png" width="672"></div>
<p>In the <code><a href="https://rdrr.io/pkg/coda/man/densplot.html">densplot()</a></code>, we can see the shape of the sampled posterior, indicative of the probability density for <span class="math inline">\(\beta\)</span>. For instance, it is clear that most of the probability mass is over the median value around -4.0, but that there is some probability mass lower, and higher; in other words there is some variation in our certainty about the true posterior spatial auto correlation value.</p>
<p>Recall that the <span class="math inline">\(\beta\)</span> represents the <em>average log-risk</em> of VLBW in Georgia. So to make these numbers more interpretable, exponentiate to get <span class="math inline">\(e^{-4.0} = 0.018\)</span>. The ‘<em>average</em>’ risk of VLBW is therefore 1.8%, and counties vary around (e.g. above and below) that value.</p>
<p>The preceding illustrations of how to examine the data and plot specific parameters could be extended well beyond the <span class="math inline">\(\beta\)</span> intercept alone! Any number of parameters could be evaluated, but remember there are <span class="math inline">\(n=159\)</span> different values for <span class="math inline">\(\psi_i\)</span>.</p>
</div>
<div id="extracting-summaries-for-mapping-or-analysis" class="section level3" number="6.3.6">
<h3>
<span class="header-section-number">6.3.6</span> Extracting summaries for mapping or analysis<a class="anchor" aria-label="anchor" href="#extracting-summaries-for-mapping-or-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>Finally, you want to extract summaries of these data for the purposes of analyzing or visualizing. The presence of 1000 samples from the posterior for every single parameter, makes working with the data cumbersome. Luckily there are some extractor functions that can help.</p>
<p>The <em>fitted values</em> are in a separate matrix within <code>samples</code>, and contain the model-predicted value of <span class="math inline">\(\hat{Y_i}\)</span> for each county. These can be useful for calculating a model-smoothed rate or risk.</p>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y_fitted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">bym</span><span class="op">)</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">rate_bym</span> <span class="op">&lt;-</span> <span class="va">y_fitted</span> <span class="op">/</span> <span class="va">vlbw</span><span class="op">$</span><span class="va">TOT</span></span></code></pre></div>
<p>The random effects, <span class="math inline">\(\psi_i\)</span>, are interpreted as the log-relative risk for each county. In other words they quantify the degree to which each county departs from the overall average (or more specifically from the global intercept, which in this case is captured in the <code>beta</code> matrix within <code>bym$samples</code> as in <code>head(bym$samples$beta)</code>).</p>
<p>We might wish to summarize the posterior of each county’s log-relative risk by taking the median of samples for <span class="math inline">\(\psi_i\)</span> (or summarise the posterior of any modeled parameter, for that matter!).</p>
<p>First, it is worth noting the data class of each of the objects containing the <code>bym$samples$psi</code>:</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">psi</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "mcmc"</code></pre>
<p>The <code>mcmc</code> data class is defined in the <code>coda</code> package, which is a toolbox of functions specific to manipulating and summarizing MCMC data objects. So the <code>bym$samples$psi</code> object is basically a Monte Carlo Markov Chain posterior summarization of a single parameter from a model. If you have loaded the package <code>coda</code>, then you will be able to use the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function on an object of class <code>mcmc</code> with success:</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load coda package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">coda</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract the median (50th percentile) and 95% credible interval of posterior of psi</span></span>
<span><span class="va">psi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">bym</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">psi</span>, quantiles <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">quantiles</span></span>
<span></span>
<span><span class="co"># Exponentiate the estimates to put them on RR scale</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">RR_bym</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">psi</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="co"># RR</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">RR_lci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">psi</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="co"># Lower 95% credible interval</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">RR_uci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">psi</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="co"># Upper 95% credible interval</span></span></code></pre></div>
</div>
<div id="plot-raw-versus-smoothed" class="section level3" number="6.3.7">
<h3>
<span class="header-section-number">6.3.7</span> Plot raw versus smoothed<a class="anchor" aria-label="anchor" href="#plot-raw-versus-smoothed"><i class="fas fa-link"></i></a>
</h3>
<p>You might be interested to see how different the Bayesian values are from the raw or observed values. We can use base-R to plot this.</p>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">$</span><span class="va">rate</span>, <span class="va">vlbw</span><span class="op">$</span><span class="va">rate_bym</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-19-1.png" width="672"></div>
<p>Just as we saw with Empirical Bayes, the Bayesian smoothed rates are smoothed towards the mean as compared with the raw values.</p>
</div>
<div id="mapping-rates" class="section level3" number="6.3.8">
<h3>
<span class="header-section-number">6.3.8</span> Mapping rates<a class="anchor" aria-label="anchor" href="#mapping-rates"><i class="fas fa-link"></i></a>
</h3>
<p>Because we have added the modeled parameters to our <code>vlbw</code> spatial object, they are ready to map.</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_fill</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'rate'</span>, <span class="st">'rate_bym'</span><span class="op">)</span>,</span>
<span>          style <span class="op">=</span> <span class="st">'quantile'</span>,</span>
<span>          palette <span class="op">=</span> <span class="st">'BuPu'</span>,</span>
<span>          title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Observed rate'</span>, <span class="st">'CAR smoothed'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_borders</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_layout.html">tm_layout</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'RIGHT'</span>, <span class="st">'TOP'</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-20-1.png" width="672"></div>
<p>Again, this map appears similar to the spatial Empirical Bayes procedure from Disease Mapping II. That makes sense because both are Bayesian and both use the same definition of spatial neighbors. The <em>value-added</em> for fully Bayesian modeling as compared with spatial Empirical Bayes smoothing include:</p>
<ul>
<li>CAR-prior Bayesian smoothing borrows strength from neighbors (like spatial EB), but also models local spatial auto correlation.</li>
<li>Bayesian modeling readily accommodates covariates into the regression, unlike the Empirical Bayes procedure from last week.</li>
<li>Sampling from the Bayesian posterior permits inference including use of 95% credible intervals and <em>exceedance probabilities</em> which was not possible with spatial EB.</li>
</ul>
</div>
<div id="mapping-exceedance-probability" class="section level3" number="6.3.9">
<h3>
<span class="header-section-number">6.3.9</span> Mapping exceedance probability<a class="anchor" aria-label="anchor" href="#mapping-exceedance-probability"><i class="fas fa-link"></i></a>
</h3>
<p>We have mentioned many times how challenging it can be to visualize both the parameter estimate, but also a measure of its precision, variance, or reliability. The nature of Bayesian inference lends itself well to characterizing the probability that the posterior is or is not consistent with some threshold. Because we can directly interpret the posterior as samples from a probability distribution, we only need to look at how many of the MCMC samples <em>exceeded</em> a given threshold in order to make inference about how confident we are in an estimate.</p>
<p>For example the random effect parameters, <span class="math inline">\(\psi_i\)</span> represent the deviation of <span class="math inline">\(region_i\)</span> from the overall mean rate value estimated by the global intercept. In other words the random effects are centered at 0 (a county with <span class="math inline">\(\psi_i\)</span> = 0 is a county with the rate = intercept value).</p>
<p>When exponentiated, we say that the <em>relative risk</em> is centered at the null value of 1. So if we mapped the relative risk (like the SMR), we’re interested in counties that are <em>different</em> from 1, or the expected value in the state.</p>
<p>To calculate the probability that each county is greater than (or less than) 0 on the log scale (or 1 on the RR scale), we simply look at the proportion of samples from the posterior that <em>exceed</em> the value. This proportion is the <em>exceedence probability</em>. Then we might summarize which counties had a very high probability of being greater than the threshold (e.g. 0).</p>
<p>Similarly, we can look at counties which had a very <em>low probability</em> of exceeding zero. What this means is that few of the samples were above zero. These are suggestive of sub-zero deviation. In this way the exceedance probability quantifies both exceedingly <em>high</em> and exceedingly <em>low</em> counties.</p>
<p>To calculate <em>exceedence probabilities</em>, we once again use the function <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code>, but this time we will focus on the specific threshold of interest. Because we are looking at the random effects, <span class="math inline">\(\psi_i\)</span>, we know that a meaningfully different value is one that is not equal to zero (the threshold would be different for different parameters, e.g. <span class="math inline">\(\sigma^2\)</span>).</p>
<p>We can use the quantiles returned from <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> in the code above. We selected the <span class="math inline">\(2.5^{th}\)</span> and <span class="math inline">\(97.5^{th}\)</span> percentile of the posterior. If we compared the actual value of those percentiles to the null we could divide estimates into those that “<em>exceed the null with 95% probability</em>” from those that do not.</p>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a 1, 0 variable in vlbw indicating P&lt;0.025 or P&gt;0.975</span></span>
<span><span class="va">vlbw</span><span class="op">$</span><span class="va">rr_95</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">$</span><span class="va">RR_lci</span> <span class="op">&gt;</span> <span class="fl">1</span>, <span class="st">'High'</span>, </span>
<span>                     <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">$</span><span class="va">RR_uci</span> <span class="op">&lt;</span> <span class="fl">1</span>, <span class="st">'Low'</span>, <span class="cn">NA</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The new variable <code>vlbw_95</code> is a three-level indicator reflecting whether counties have significantly <em>lower</em> risk than average (e.g. their upper credible interval smaller than the null of 1), significantly <em>higher</em> risk than average (e.g. their lower credible interval is larger than the null of 1), or whether the posterior estimate for that county is consistent with the state average (e.g. there is a decent probability that the estimate of <span class="math inline">\(psi_i\)</span> is not actually different from the state expectation).</p>
<p>It is worth noting here that Bayesian’s typically do not talk about <em>significance</em> in the same way as frequentist’s. We are inherently estimating posterior distributions, rather than testing discrete null hypotheses. However, for ease, I have used the word <em>significance</em> to describe the posteriors which have their 95% credible interval excluding the zero value.</p>
<p>There are several ways we could incorporate this new information into a map, but below are two simple versions. In this first, I layer three shapes on top of one another; the first has the county values, the second is only the borders for the counties that are lower than average, and the third is only the borders for counties that are higher than average.</p>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_fill</a></span><span class="op">(</span><span class="st">'RR_bym'</span>,</span>
<span>          style <span class="op">=</span> <span class="st">'fixed'</span>,</span>
<span>          palette <span class="op">=</span> <span class="st">'PRGn'</span>,</span>
<span>          breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.13</span>, <span class="fl">0.67</span>, <span class="fl">0.9</span>, <span class="fl">1.1</span>, <span class="fl">1.4</span>, <span class="fl">2.3</span><span class="op">)</span>,</span>
<span>          title <span class="op">=</span> <span class="st">'Relative Risk'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_borders</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">vlbw</span>, <span class="va">rr_95</span> <span class="op">==</span> <span class="st">'Low'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_borders</a></span><span class="op">(</span>col <span class="op">=</span> <span class="st">'purple'</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">vlbw</span>, <span class="va">rr_95</span> <span class="op">==</span> <span class="st">'High'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_borders</a></span><span class="op">(</span>col <span class="op">=</span> <span class="st">'green'</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_add_legend.html">tm_add_legend</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">'line'</span>, </span>
<span>                labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Low risk county'</span>, <span class="st">'High risk county'</span><span class="op">)</span>, </span>
<span>                col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'purple'</span>,<span class="st">'green'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_layout.html">tm_layout</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'RIGHT'</span>,<span class="st">'TOP'</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-22-1.png" width="672"></div>
<p>Here is an alternative approach using <code><a href="https://r-tmap.github.io/tmap/reference/tm_symbols.html">tm_symbols()</a></code> to plot colored symbols on the <em>high</em> and <em>low</em> counties.</p>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_fill</a></span><span class="op">(</span><span class="st">'RR_bym'</span>,</span>
<span>          style <span class="op">=</span> <span class="st">'fixed'</span>,</span>
<span>          palette <span class="op">=</span> <span class="st">'PRGn'</span>,</span>
<span>          breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.13</span>, <span class="fl">0.67</span>, <span class="fl">0.9</span>, <span class="fl">1.1</span>, <span class="fl">1.4</span>, <span class="fl">2.3</span><span class="op">)</span>,</span>
<span>          title <span class="op">=</span> <span class="st">'Relative Risk'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_polygons.html">tm_borders</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_shape.html">tm_shape</a></span><span class="op">(</span><span class="va">vlbw</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_symbols.html">tm_symbols</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="st">'rr_95'</span>,</span>
<span>             col <span class="op">=</span> <span class="st">'rr_95'</span>,</span>
<span>             palette <span class="op">=</span> <span class="st">'Dark2'</span>,</span>
<span>             size <span class="op">=</span> <span class="fl">.5</span>,</span>
<span>             shapeNA <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>             showNA <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>             legend.shape.show <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>            title.col <span class="op">=</span> <span class="st">'Significance'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://r-tmap.github.io/tmap/reference/tm_layout.html">tm_layout</a></span><span class="op">(</span>legend.outside <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-disease-mapping-3_files/figure-html/unnamed-chunk-23-1.png" width="672"></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="disease-mapping-ii-spatial-empirical-bayes.html"><span class="header-section-number">5</span> Disease Mapping II: Spatial Empirical Bayes</a></div>
<div class="next"><a href="disease-mapping-iv-kernel-density-estimation.html"><span class="header-section-number">7</span> Disease Mapping IV: Kernel Density Estimation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#disease-mapping-iii-introduction-to-fully-bayesian-mapping"><span class="header-section-number">6</span> Disease Mapping III: Introduction to Fully Bayesian mapping</a></li>
<li>
<a class="nav-link" href="#getting-ready-4"><span class="header-section-number">6.1</span> Getting Ready</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#learning-objectives-5"><span class="header-section-number">6.1.1</span> Learning objectives</a></li>
<li><a class="nav-link" href="#additional-resources-5"><span class="header-section-number">6.1.2</span> Additional Resources</a></li>
<li><a class="nav-link" href="#important-vocabulary-5"><span class="header-section-number">6.1.3</span> Important Vocabulary</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#spatial-thinking-in-epidemiology-4"><span class="header-section-number">6.2</span> Spatial Thinking in Epidemiology</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#what-is-bayesian-inference"><span class="header-section-number">6.2.1</span> What is Bayesian Inference?</a></li>
<li><a class="nav-link" href="#bayesian-inference-in-spatial-epidemiology"><span class="header-section-number">6.2.2</span> Bayesian inference in spatial epidemiology</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#spatial-analysis-in-epidemiology-4"><span class="header-section-number">6.3</span> Spatial Analysis in Epidemiology</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#packages-data"><span class="header-section-number">6.3.1</span> Packages &amp; Data</a></li>
<li><a class="nav-link" href="#preparing-for-carbayes"><span class="header-section-number">6.3.2</span> Preparing for CARBayes()</a></li>
<li><a class="nav-link" href="#fitting-a-besag-york-mollie-bym-bayesian-model"><span class="header-section-number">6.3.3</span> Fitting a Besag-York-Mollie (BYM) Bayesian model</a></li>
<li><a class="nav-link" href="#summarizing-carbayes-model-output"><span class="header-section-number">6.3.4</span> Summarizing CARBayes model output</a></li>
<li><a class="nav-link" href="#making-inference-from-bayesian-posteriors"><span class="header-section-number">6.3.5</span> Making inference from Bayesian posteriors</a></li>
<li><a class="nav-link" href="#extracting-summaries-for-mapping-or-analysis"><span class="header-section-number">6.3.6</span> Extracting summaries for mapping or analysis</a></li>
<li><a class="nav-link" href="#plot-raw-versus-smoothed"><span class="header-section-number">6.3.7</span> Plot raw versus smoothed</a></li>
<li><a class="nav-link" href="#mapping-rates"><span class="header-section-number">6.3.8</span> Mapping rates</a></li>
<li><a class="nav-link" href="#mapping-exceedance-probability"><span class="header-section-number">6.3.9</span> Mapping exceedance probability</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mkram01/EPI563-SpatialEPI/blob/master/06-disease-mapping-3.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mkram01/EPI563-SpatialEPI/edit/master/06-disease-mapping-3.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>EPI 563: Spatial Epidemiology, Fall 2023</strong>" was written by Michael Kramer. It was last built on Last updated: 2023-10-11.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
